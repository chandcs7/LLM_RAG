{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "16c33457a8a641ae82e56290ad743ab8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2099c9288e3f4f61870a3d419305e383",
       "IPY_MODEL_f01592bb1638481dba974d89f0798f3c",
       "IPY_MODEL_1ae0b92575b54a76b3a22831f9130a18"
      ],
      "layout": "IPY_MODEL_d437c527f9594a3f9cbec4d977b9da1d"
     }
    },
    "2099c9288e3f4f61870a3d419305e383": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d18b408d81f44c8c8d262736c6fe16e3",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_160b083072b2408a99aa660662741db8",
      "value": "Loading\u2007weights:\u2007100%"
     }
    },
    "f01592bb1638481dba974d89f0798f3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39030c8266af4b0185ea4a426ef6bad4",
      "max": 103,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9e8a683ee40e47be9958ea617c4a0db4",
      "value": 103
     }
    },
    "1ae0b92575b54a76b3a22831f9130a18": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2062881d27d14185bad4c10151ef47c1",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_f9151dfbc05c42c68f9a7ea21ba35ab6",
      "value": "\u2007103/103\u2007[00:00&lt;00:00,\u2007185.84it/s,\u2007Materializing\u2007param=pooler.dense.weight]"
     }
    },
    "d437c527f9594a3f9cbec4d977b9da1d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d18b408d81f44c8c8d262736c6fe16e3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "160b083072b2408a99aa660662741db8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "39030c8266af4b0185ea4a426ef6bad4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e8a683ee40e47be9958ea617c4a0db4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2062881d27d14185bad4c10151ef47c1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9151dfbc05c42c68f9a7ea21ba35ab6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "83a28d3d5291445093b48884b3e998d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c0b5e6678b7e43199b688a87e0ceabc0",
       "IPY_MODEL_dd589ebcd6134ab9b28c20efd13f7246",
       "IPY_MODEL_ed3fe0cd475949e0839d44ed8bde14bf"
      ],
      "layout": "IPY_MODEL_f01d2500d3d14217905120082efe1c7f"
     }
    },
    "c0b5e6678b7e43199b688a87e0ceabc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c7a5930f8cc94e57950fbdf87d138f3c",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_fc2a91ecf9b54964b08a0b17d823c44a",
      "value": "Loading\u2007weights:\u2007100%"
     }
    },
    "dd589ebcd6134ab9b28c20efd13f7246": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_173abe5ed0674cd9aba66aa85a22055a",
      "max": 453,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aa3fc954e0994dc88e842d1d0f384ceb",
      "value": 453
     }
    },
    "ed3fe0cd475949e0839d44ed8bde14bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa407374c34b4795b9595c4eb2c90c93",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_3a99ea66b91c4e6d8a4af92f3d45617a",
      "value": "\u2007453/453\u2007[08:14&lt;00:00,\u2007\u20071.13it/s,\u2007Materializing\u2007param=model.layers.31.self_attn.v_proj.weight]"
     }
    },
    "f01d2500d3d14217905120082efe1c7f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7a5930f8cc94e57950fbdf87d138f3c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc2a91ecf9b54964b08a0b17d823c44a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "173abe5ed0674cd9aba66aa85a22055a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa3fc954e0994dc88e842d1d0f384ceb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fa407374c34b4795b9595c4eb2c90c93": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a99ea66b91c4e6d8a4af92f3d45617a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ca67ae2967c641468625cb95b9e928fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1da0c64bca89403c8072b1989453fa03",
       "IPY_MODEL_d22f965466ed4b78a15d144ee560ad55",
       "IPY_MODEL_d424c00d9fb94f848f8066a3f40295b7"
      ],
      "layout": "IPY_MODEL_b2c61b75cd514c87bda7c27fe14b7b44"
     }
    },
    "1da0c64bca89403c8072b1989453fa03": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b33c78b7a274e729354f7ab2e008cb7",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_e655b426e33644f7a922881c2b3d974c",
      "value": "Loading\u2007weights:\u2007100%"
     }
    },
    "d22f965466ed4b78a15d144ee560ad55": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dee4cc93fbc346b9823bde4b6e2e2ca7",
      "max": 105,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_38a0c3de74dc4b7caa85ec2c5fd574be",
      "value": 105
     }
    },
    "d424c00d9fb94f848f8066a3f40295b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e8abb09c257e4a5e9d6c500170e05936",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_deec07755ff44114ae2c101823b69276",
      "value": "\u2007105/105\u2007[00:00&lt;00:00,\u2007257.40it/s,\u2007Materializing\u2007param=classifier.weight]"
     }
    },
    "b2c61b75cd514c87bda7c27fe14b7b44": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b33c78b7a274e729354f7ab2e008cb7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e655b426e33644f7a922881c2b3d974c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dee4cc93fbc346b9823bde4b6e2e2ca7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38a0c3de74dc4b7caa85ec2c5fd574be": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e8abb09c257e4a5e9d6c500170e05936": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "deec07755ff44114ae2c101823b69276": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "DaYtCxP7Sosv",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1770991176860,
     "user_tz": -330,
     "elapsed": 7772,
     "user": {
      "displayName": "chandni bharadwaj",
      "userId": "09360863509766162657"
     }
    },
    "outputId": "86a39854-5361-4413-d925-5419e6947de3"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Retrieving folder contents\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing file 1RIgnFDnFbzMLyNLxT1AQEg7wlmNa2lZO Apple_10-Q4-2024-As-Filed.pdf\n",
      "Processing file 1PrMab5gI8PcY-33-e4ishPJoqZUr1YVw Tesla_NASDAQ_TSLA_2023.pdf\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Retrieving folder contents completed\n",
      "Building directory structure\n",
      "Building directory structure completed\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1RIgnFDnFbzMLyNLxT1AQEg7wlmNa2lZO\n",
      "To: /content/ABB_LLM/Apple_10-Q4-2024-As-Filed.pdf\n",
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 964k/964k [00:00<00:00, 30.4MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1PrMab5gI8PcY-33-e4ishPJoqZUr1YVw\n",
      "To: /content/ABB_LLM/Tesla_NASDAQ_TSLA_2023.pdf\n",
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 985k/985k [00:00<00:00, 10.4MB/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Attempted to download folder contents.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "Download completed\n"
     ]
    }
   ],
   "source": [
    "import gdown\n",
    "import os\n",
    "\n",
    "url = \"https://drive.google.com/drive/u/0/folders/1Oiq2ubkNc5xoN4dQDI3UYdYB1vGgYaJP\"\n",
    "\n",
    "gdown.download_folder(url, remaining_ok=True, use_cookies=False)\n",
    "print(\"Attempted to download folder contents.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install pymupdf\n",
    "import pandas as pd\n",
    "import fitz\n",
    "import os\n",
    "import re\n",
    "!pip install langchain-text-splitters\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "!pip install chromadb sentence-transformers rfc3987\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "import uuid\n",
    "print('ChromaDB and dependencies successfully installed and imported.')\n",
    "!pip install -q sentence-transformers\n",
    "from sentence_transformers import CrossEncoder\n",
    "import chromadb"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "4V7sjcP9TG7s",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1770991241187,
     "user_tz": -330,
     "elapsed": 64322,
     "user": {
      "displayName": "chandni bharadwaj",
      "userId": "09360863509766162657"
     }
    },
    "outputId": "4c15e99c-ba4d-4c7e-fda9-a2ba0a26e879"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: pymupdf in /usr/local/lib/python3.12/dist-packages (1.27.1)\n",
      "Requirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-text-splitters) (1.2.9)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.6.9)\n",
      "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (26.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.12.3)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (9.1.3)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.11.7)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.32.4)\n",
      "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.6.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.4.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (4.12.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.5.0)\n",
      "Requirement already satisfied: chromadb in /usr/local/lib/python3.12/dist-packages (1.5.0)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.2)\n",
      "Requirement already satisfied: rfc3987 in /usr/local/lib/python3.12/dist-packages (1.3.8)\n",
      "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.4.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.12.3)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.4.3)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.40.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.0.2)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.15.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.24.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.39.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.2)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.51.1)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.3)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.76.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.0.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.21.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (35.0.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (9.1.3)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.0.3)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.7)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.26.0)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (5.0.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.4.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cpu)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
      "Requirement already satisfied: packaging>=24.0 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (26.0)\n",
      "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.12.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.30.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.4)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: urllib3!=2.6.0,>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.12.19)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.6)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.60b1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.4.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.1)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.2.1)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "ChromaDB and dependencies successfully installed and imported.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# initialize global list to avoid duplicate entries from previous runs\n",
    "!pip install pymupdf\n",
    "import pandas as pd\n",
    "import fitz\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import fitz\n",
    "import os\n",
    "import re\n",
    "\n",
    "structured_data = []\n",
    "\n",
    "pdf_dir = '/content/ABB_LLM/'\n",
    "file_paths = [os.path.join(pdf_dir, f) for f in os.listdir(pdf_dir) if f.endswith('.pdf')]\n",
    "SECTION_HEADER_PATTERN = re.compile(r'(?i)^\\s*(Item\\s+\\d+[A-Z]?)\\b', re.MULTILINE)\n",
    "\n",
    "def process_pdf_with_tables(file_path):\n",
    "    filename = os.path.basename(file_path)\n",
    "    doc = fitz.open(file_path)\n",
    "    current_section = \"Unknown\"\n",
    "\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "\n",
    "        # 1. Extract standard text\n",
    "        raw_text = page.get_text(\"text\")\n",
    "\n",
    "        # 2. Extract tables and convert to Markdown strings\n",
    "        table_texts = []\n",
    "        tabs = page.find_tables()\n",
    "        for tab in tabs:\n",
    "            df_tab = tab.to_pandas()\n",
    "            if not df_tab.empty:\n",
    "                # Convert table to markdown format to preserve structure\n",
    "                table_texts.append(df_tab.to_markdown(index=False))\n",
    "\n",
    "        # 3. Combine text and tables\n",
    "        combined_content = raw_text\n",
    "        if table_texts:\n",
    "            combined_content += \"\\n\\n### Tables Extracted:\\n\" + \"\\n\\n\".join(table_texts)\n",
    "\n",
    "        # 4. Cleaning\n",
    "        cleaned_text = re.sub(r'\\n{2,}', '\\n\\n', combined_content)\n",
    "        cleaned_text = re.sub(r' +', ' ', cleaned_text).strip()\n",
    "\n",
    "        # Detect section\n",
    "        section_match = SECTION_HEADER_PATTERN.search(cleaned_text)\n",
    "        if section_match:\n",
    "            current_section = section_match.group(1).upper()\n",
    "\n",
    "        structured_data.append({\n",
    "            'filename': filename,\n",
    "            'page_number': page_num + 1,\n",
    "            'section': current_section,\n",
    "            'content': cleaned_text\n",
    "        })\n",
    "    doc.close()\n",
    "\n",
    "# Execute processing\n",
    "for path in file_paths:\n",
    "   process_pdf_with_tables(path)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9YhtYTBTL0z",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1770991347604,
     "user_tz": -330,
     "elapsed": 106405,
     "user": {
      "displayName": "chandni bharadwaj",
      "userId": "09360863509766162657"
     }
    },
    "outputId": "ae13ee9e-1a8c-461b-ac44-8c67965487bc",
    "collapsed": true
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: pymupdf in /usr/local/lib/python3.12/dist-packages (1.27.1)\n",
      "Consider using the pymupdf_layout package for a greatly improved page layout analysis.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 1. Initialize the splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "enriched_chunks = []\n",
    "\n",
    "# 2. Iterate through structured_data to split content\n",
    "for page in structured_data:\n",
    "    segments = text_splitter.split_text(page['content'])\n",
    "    for segment in segments:\n",
    "        enriched_chunks.append({\n",
    "            \"text\": segment,\n",
    "            \"metadata\": {\n",
    "                \"filename\": page['filename'],\n",
    "                \"page_number\": page['page_number'],\n",
    "                \"section\": page['section']\n",
    "            }\n",
    "        })\n",
    "\n",
    "# 3. Verify the process\n",
    "print(f\"Total enriched chunks generated: {len(enriched_chunks)}\")\n",
    "if enriched_chunks:\n",
    "    print(f\"Sample chunk metadata: {enriched_chunks[0]['metadata']}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y_8VQ0nhTZZy",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1770991347637,
     "user_tz": -330,
     "elapsed": 20,
     "user": {
      "displayName": "chandni bharadwaj",
      "userId": "09360863509766162657"
     }
    },
    "outputId": "8b8915ed-c18e-40ff-d4a2-cc97269b4bca",
    "collapsed": true
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total enriched chunks generated: 1168\n",
      "Sample chunk metadata: {'filename': 'Apple_10-Q4-2024-As-Filed.pdf', 'page_number': 1, 'section': 'Unknown'}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "import uuid\n",
    "print('ChromaDB and dependencies successfully installed and imported.')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vnauGRiUTiTX",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1770991347656,
     "user_tz": -330,
     "elapsed": 14,
     "user": {
      "displayName": "chandni bharadwaj",
      "userId": "09360863509766162657"
     }
    },
    "outputId": "c5472ffe-2f2b-4028-ca5f-d4d1fe4a6f5d",
    "collapsed": true
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ChromaDB and dependencies successfully installed and imported.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Initialize persistent client using the Drive path\n",
    "client = chromadb.PersistentClient(path='./chroma_db_storage')\n",
    "\n",
    "# 2. Define embedding function\n",
    "embedding_func = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "    model_name='all-MiniLM-L6-v2'\n",
    ")\n",
    "\n",
    "# 3. Delete existing collection if it exists\n",
    "try:\n",
    "    client.delete_collection(name='filings_appletesla')\n",
    "    print(\"Deleted existing collection 'filings_appletesla'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Collection not found or could not be deleted: {e}\")\n",
    "\n",
    "# 4. Create new collection\n",
    "collection = client.create_collection(\n",
    "    name='filings_appletesla',\n",
    "    embedding_function=embedding_func\n",
    ")\n",
    "\n",
    "# 5. Prepare data for ingestion\n",
    "documents = [chunk['text'] for chunk in enriched_chunks]\n",
    "metadatas = [chunk['metadata'] for chunk in enriched_chunks]\n",
    "ids = [str(uuid.uuid4()) for _ in range(len(enriched_chunks))]\n",
    "\n",
    "# 6. Ingest data\n",
    "collection.add(\n",
    "    documents=documents,\n",
    "    metadatas=metadatas,\n",
    "    ids=ids\n",
    ")\n",
    "\n",
    "print(f\"Successfully re-initialized collection '{collection.name}'\")\n",
    "print(f\"Total records stored: {collection.count()}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381,
     "referenced_widgets": [
      "16c33457a8a641ae82e56290ad743ab8",
      "2099c9288e3f4f61870a3d419305e383",
      "f01592bb1638481dba974d89f0798f3c",
      "1ae0b92575b54a76b3a22831f9130a18",
      "d437c527f9594a3f9cbec4d977b9da1d",
      "d18b408d81f44c8c8d262736c6fe16e3",
      "160b083072b2408a99aa660662741db8",
      "39030c8266af4b0185ea4a426ef6bad4",
      "9e8a683ee40e47be9958ea617c4a0db4",
      "2062881d27d14185bad4c10151ef47c1",
      "f9151dfbc05c42c68f9a7ea21ba35ab6"
     ]
    },
    "collapsed": true,
    "id": "swq_xU0XTm3D",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1770991535230,
     "user_tz": -330,
     "elapsed": 187572,
     "user": {
      "displayName": "chandni bharadwaj",
      "userId": "09360863509766162657"
     }
    },
    "outputId": "5a7aab6f-1341-4093-a4dd-7b16e2cd2de0"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "16c33457a8a641ae82e56290ad743ab8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Deleted existing collection 'filings_appletesla'.\n",
      "Successfully re-initialized collection 'filings_appletesla' on Drive.\n",
      "Total records stored: 1168\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -q transformers accelerate\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "print(f'Transformers version: {transformers.__version__}')\n",
    "\n",
    "# Check for GPU availability\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "if device == 'cuda':\n",
    "    print(f'GPU Name: {torch.cuda.get_device_name(0)}')\n",
    "else:\n",
    "    print('Warning: No GPU detected. LLM inference will be slow on CPU.')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "MPvNYJVJT56E",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1770991547016,
     "user_tz": -330,
     "elapsed": 11789,
     "user": {
      "displayName": "chandni bharadwaj",
      "userId": "09360863509766162657"
     }
    },
    "outputId": "b389a474-56dc-4163-9bdf-f7f865165cdc"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Transformers version: 5.0.0\n",
      "Using device: cpu\n",
      "Warning: No GPU detected. LLM inference will be slow on CPU.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the custom RAG prompt template with strict citation enforcement\n",
    "rag_prompt_template = \"\"\"\n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "\n",
    "--- INSTRUCTIONS ---\n",
    "1. Use ONLY the information provided in the Context sources.\n",
    "2. If the answer is not contained within the context (e.g. asking for future years not in the text), clearly state: \\\"Not Answerable\\\".\n",
    "3. You MUST provide the answer followed by the exact citation in this format: [Filename, Section, Page X].\n",
    "4. Do not write full sentences, just provide the data and the citation separating with comma.\n",
    "5. If the context does not contain the specific year or data point requested, do not guess. Say \\\"Not Answerable\\\".\n",
    "6. If the context does not contain specific information within the context(e.g. asking how are you) Say \\\"Not Answerable\\\" and dont provide any citation details.\n",
    "7. CRITICAL: If the answer is \\\"Not Answerable\\\", do NOT provide any citation, headers, or source information.\n",
    "\n",
    "--- CONTEXT ---\n",
    "{context}\n",
    "\n",
    "--- QUESTION ---\n",
    "{query}\n",
    "\n",
    "--- ANSWER ---\n",
    "\"\"\"\n",
    "\n",
    "print(\"RAG prompt template updated for strict validation.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RW5QyGZ1UsOX",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1770991547047,
     "user_tz": -330,
     "elapsed": 7,
     "user": {
      "displayName": "chandni bharadwaj",
      "userId": "09360863509766162657"
     }
    },
    "outputId": "f755d6b0-7f04-4246-e59e-205a97e21446"
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RAG prompt template updated for strict validation.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#avoid crashing of session and for memory efficient loading\n",
    "!pip install -q bitsandbytes accelerate\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "def clear_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "clear_memory()\n",
    "print(\"Memory cleared and optimization libraries installed.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4LkAXi7SxPC8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1770991560076,
     "user_tz": -330,
     "elapsed": 13028,
     "user": {
      "displayName": "chandni bharadwaj",
      "userId": "09360863509766162657"
     }
    },
    "outputId": "4c141baf-4874-4dfb-aff7-ee906d12e6c1",
    "collapsed": true
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Memory cleared and optimization libraries installed.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import gc\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoConfig, BitsAndBytesConfig\n",
    "\n",
    "model_id = \"microsoft/phi-2\"\n",
    "print(\"Loading Phi-2 optimized for CPU usage...\")\n",
    "\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    # 1. Config with padding fixed\n",
    "    config = AutoConfig.from_pretrained(model_id, trust_remote_code=True)\n",
    "    config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "    # 2. Load model in 4-bit for memory efficiency\n",
    "    # On CPU, bitsandbytes handles the dequantization overhead\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        config=config,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map={ \"\": \"cpu\" },\n",
    "        trust_remote_code=True,\n",
    "        low_cpu_mem_usage=True\n",
    "    )\n",
    "\n",
    "    rag_pipeline = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    print(\"Phi-2 loaded successfully for CPU inference.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "\n",
    "def generate_rag_answer(query, ranked_chunks, top_n=1):\n",
    "    # We use top_n=1 to minimize the number of tokens the CPU has to process\n",
    "    context_segments = []\n",
    "    for i, chunk in enumerate(ranked_chunks[:top_n]):\n",
    "        source_info = f\"[Source: {chunk['metadata']['filename']}, Section: {chunk['metadata']['section']}, Page: {chunk['metadata']['page_number']}]\"\n",
    "        context_segments.append(f\"{source_info}\\n{chunk['text']}\")\n",
    "\n",
    "    aggregated_context = \"\\n\\n\".join(context_segments)\n",
    "    final_prompt = rag_prompt_template.format(context=aggregated_context, query=query)\n",
    "\n",
    "    # Limiting max_new_tokens for faster CPU response\n",
    "    sequences = rag_pipeline(\n",
    "        final_prompt,\n",
    "        max_new_tokens=50,\n",
    "        do_sample=False,\n",
    "        return_full_text=False,\n",
    "        pad_token_id=tokenizer.pad_token_id\n",
    "    )\n",
    "\n",
    "    return sequences[0]['generated_text']"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "83a28d3d5291445093b48884b3e998d1",
      "c0b5e6678b7e43199b688a87e0ceabc0",
      "dd589ebcd6134ab9b28c20efd13f7246",
      "ed3fe0cd475949e0839d44ed8bde14bf",
      "f01d2500d3d14217905120082efe1c7f",
      "c7a5930f8cc94e57950fbdf87d138f3c",
      "fc2a91ecf9b54964b08a0b17d823c44a",
      "173abe5ed0674cd9aba66aa85a22055a",
      "aa3fc954e0994dc88e842d1d0f384ceb",
      "fa407374c34b4795b9595c4eb2c90c93",
      "3a99ea66b91c4e6d8a4af92f3d45617a"
     ]
    },
    "collapsed": true,
    "id": "Fk5CDi9cU2MK",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1770992066818,
     "user_tz": -330,
     "elapsed": 506724,
     "user": {
      "displayName": "chandni bharadwaj",
      "userId": "09360863509766162657"
     }
    },
    "outputId": "0a42a1a8-9f5c-43dc-e6bf-f773e480351f"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading Phi-2 optimized for CPU usage...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading weights:   0%|          | 0/453 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "83a28d3d5291445093b48884b3e998d1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Phi-2 loaded successfully for CPU inference.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5a5662bd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1770992067492,
     "user_tz": -330,
     "elapsed": 671,
     "user": {
      "displayName": "chandni bharadwaj",
      "userId": "09360863509766162657"
     }
    },
    "outputId": "522dfa36-ca1b-4668-c149-98c6b3e802ca"
   },
   "source": [
    "import gc\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def optimize_session():\n",
    "    \"\"\"Clears memory and optimizes the environment for full execution.\"\"\"\n",
    "    # 1. Clear Python garbage collector\n",
    "    gc.collect()\n",
    "\n",
    "    # 2. Clear Torch cache (works for both CPU and GPU)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # 3. Inform the system to prioritize memory for the current process\n",
    "    print(\"Memory optimization complete. Ready for sequential execution.\")\n",
    "\n",
    "# Run optimization\n",
    "optimize_session()"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Memory optimization complete. Ready for sequential execution.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9de8be36"
   },
   "source": [
    "### Tips for a Stable Session:\n",
    "- **Sequential Execution**: Avoid running multiple intensive cells (like model loading and PDF processing) simultaneously.\n",
    "- **Restart Runtime**: If you have been experimenting for a while, go to `Runtime > Restart session` before doing a 'Run All' to ensure a clean memory state.\n",
    "- **Variable Reuse**: Avoid creating many large intermediate lists; for example, clear `structured_data` if you have already converted it into `enriched_chunks`."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "# 1. pre-loaded models\n",
    "if 'rerank_model' not in globals():\n",
    "    from sentence_transformers import CrossEncoder\n",
    "    rerank_model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2', device='cpu')\n",
    "\n",
    "# 2. Re-defining the generation logic in one place\n",
    "def generate_fast_answer(query, top_chunk):\n",
    "    source_info = f\"[Source: {top_chunk['metadata']['filename']}, Section: {top_chunk['metadata']['section']}, Page: {top_chunk['metadata']['page_number']}]\"\n",
    "    context = f\"{source_info}\\n{top_chunk['text']}\"\n",
    "\n",
    "    # Use the pre-defined strict RAG prompt\n",
    "    final_prompt = rag_prompt_template.format(context=context, query=query)\n",
    "\n",
    "    # Optimization for CPU: Increased max_new_tokens to 60 to ensure citation fits\n",
    "    with torch.no_grad():\n",
    "        sequences = rag_pipeline(\n",
    "            final_prompt,\n",
    "            max_new_tokens=60,\n",
    "            do_sample=False,\n",
    "            return_full_text=False,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    raw_answer = sequences[0]['generated_text']\n",
    "    # Post-processing: remove model artifacts but keep the citation\n",
    "    # We split by '---' and 'EXAMPLES' which are common markers where Phi-2 starts hallucinating\n",
    "    clean_answer = raw_answer.split('---')[0].split('EXAMPLES')[0].strip()\n",
    "    return clean_answer\n",
    "\n",
    "# 3. Execution Block\n",
    "start_time = time.time()\n",
    "query = \"What was Apples total revenue for the fiscal year ended September 28, 2024?\"\n",
    "\n",
    "# Retrieval\n",
    "collection = client.get_collection(name='filings_appletesla', embedding_function=embedding_func)\n",
    "results = collection.query(query_texts=[query], n_results=3)\n",
    "candidates = results['documents'][0]\n",
    "metadatas = results['metadatas'][0]\n",
    "\n",
    "# Re-ranking\n",
    "pairs = [[query, doc] for doc in candidates]\n",
    "scores = rerank_model.predict(pairs)\n",
    "\n",
    "ranked_results = []\n",
    "for i in range(len(candidates)):\n",
    "    ranked_results.append({\"text\": candidates[i], \"metadata\": metadatas[i], \"score\": scores[i]})\n",
    "ranked_results = sorted(ranked_results, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "# Generation\n",
    "answer = generate_fast_answer(query, ranked_results[0])\n",
    "\n",
    "duration = time.time() - start_time\n",
    "print(f\"\\n--- RESULTS (Total Time: {duration:.2f}s) ---\")\n",
    "print(answer)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295,
     "referenced_widgets": [
      "ca67ae2967c641468625cb95b9e928fd",
      "1da0c64bca89403c8072b1989453fa03",
      "d22f965466ed4b78a15d144ee560ad55",
      "d424c00d9fb94f848f8066a3f40295b7",
      "b2c61b75cd514c87bda7c27fe14b7b44",
      "4b33c78b7a274e729354f7ab2e008cb7",
      "e655b426e33644f7a922881c2b3d974c",
      "dee4cc93fbc346b9823bde4b6e2e2ca7",
      "38a0c3de74dc4b7caa85ec2c5fd574be",
      "e8abb09c257e4a5e9d6c500170e05936",
      "deec07755ff44114ae2c101823b69276"
     ]
    },
    "collapsed": true,
    "id": "4rYuctvKU-hl",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1770993603178,
     "user_tz": -330,
     "elapsed": 1535684,
     "user": {
      "displayName": "chandni bharadwaj",
      "userId": "09360863509766162657"
     }
    },
    "outputId": "470be7df-8295-47f8-ccd1-91553df2a142"
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading weights:   0%|          | 0/105 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ca67ae2967c641468625cb95b9e928fd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "BertForSequenceClassification LOAD REPORT from: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
      "Key                          | Status     |  | \n",
      "-----------------------------+------------+--+-\n",
      "bert.embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Passing `generation_config` together with generation-related arguments=({'pad_token_id', 'do_sample', 'max_new_tokens', 'eos_token_id'}) is deprecated and will be removed in future versions. Please pass either a `generation_config` object OR all generation parameters explicitly, but not both.\n",
      "Both `max_new_tokens` (=30) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "--- RESULTS (Total Time: 1533.35s) ---\n",
      "$391,035\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "import os\n",
    "from google.colab import _message\n",
    "\n",
    "# 1. Configuration\n",
    "GITHUB_USER = 'REDACTED'\n",
    "GITHUB_REPO = \"LLM_RAG\"\n",
    "GITHUB_TOKEN = 'REDACTED'\n",
    "GITHUB_EMAIL = 'REDACTED'\n",
    "notebook_filename = \"RAG_Pipeline_Notebook.ipynb\"\n",
    "\n",
    "# 2. Get and Redact the Notebook\n",
    "notebook_json = _message.blocking_request(\"get_ipynb\", request=\"\", timeout_sec=30)\n",
    "nb_data = notebook_json[\"ipynb\"]\n",
    "\n",
    "for cell in nb_data.get(\"cells\", []):\n",
    "    if cell.get(\"cell_type\") == \"code\":\n",
    "        lines = cell.get(\"source\", [])\n",
    "        new_source = []\n",
    "        for line in lines:\n",
    "# Secret Redacted\n",
    "                if \"=\" in line:\n",
    "                    key = line.split(\"=\")[0].strip()\n",
    "                    new_source.append(f\"{key} = 'REDACTED'\\n\")\n",
    "                else:\n",
    "                    new_source.append(\"# Secret Redacted\\n\")\n",
    "            else:\n",
    "                new_source.append(line)\n",
    "        cell[\"source\"] = new_source\n",
    "\n",
    "with open(notebook_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(nb_data, f, indent=1)\n",
    "\n",
    "# 3. Git Operations for ALL files\n",
    "# Secret Redacted\n",
    "# Secret Redacted\n",
    "\n",
    "# Wipe and re-init to ensure a clean push of everything\n",
    "!rm -rf .git\n",
    "!git init\n",
    "!git add .\n",
    "!git commit -m \"Full repository push including redacted notebook and data files\"\n",
    "\n",
    "remote_url = 'REDACTED'\n",
    "!git remote add origin {remote_url}\n",
    "!git branch -M main\n",
    "!git push -u origin main --force\n",
    "\n",
    "print(f\"\\nSuccessfully pushed all files and {notebook_filename} to GitHub!\")"
   ],
   "metadata": {
    "id": "CNU3PKr3hRU-"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}